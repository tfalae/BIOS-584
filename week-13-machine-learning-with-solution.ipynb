{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aea4d09-f1d5-41fd-ad9b-575d3ea6d115",
   "metadata": {},
   "source": [
    "# Week-13: Classification Task in Python\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Welcome back!\n",
    "* Today, we will go over a classification example using `skicit-learn` package in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da1bf4b-f6fe-4af6-aa0c-0facdc41ec3d",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "* HW8 Q1: The location of files are misplaced. Suppose that `python_proj` is your working directory, <br> `HW8_main.py` should be put right under `python_proj`, while `HW8Fun.py` should be put under `self_py_fun` folder.\n",
    "* Interpretation of parameters of the linear model is not correct:\n",
    "<img src=\"figures/HW8_linear_model_output.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "* For continuous covariate, i.e., CTQ total score, you should write:\n",
    "    * One score increase in CTQ total score, on average, corresponds to a 0.042 score increase in PCL5 score at intake, adjusting for other covariates (p=0.025, 95% CI: [0.003, 0.081]).\n",
    "* For categorical covariate, i.e., military rank, you should have reference group:\n",
    "    * Patients who are officers, on average, had lower PCL5 score at intake by 3.06 than patients who are enlisted, adjusting for other covariates (p=0.022, 95% CI: [0.44, 5.67]). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa492eb-75f3-4984-89d1-3f8dbc75c1e1",
   "metadata": {},
   "source": [
    "## Import data\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* `Scikit-learn`, known as `sklearn`, is an open-source, robust library for machine learning in Python.\n",
    "* It is created to streamline the process of implementing machine learning and statistical models in Python.\n",
    "* The package comes with standard machine learning datasets, and you can import it without downloading them from an external website or database.\n",
    "* Since we will go over a classification example, we will be using the [`wine dataset`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine) (Click it for more information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "223e4dda-3948-42c5-a85f-cf78f2313181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c7784c3c-f727-4d4f-9059-d60534adb560",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa967e98-158c-4c66-9884-9f1dae36d3f0",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "* Executing the above code returns a dictionary-like object (we just learned!) that contains data and metadata.\n",
    "    * **Metadata**: This is a terminology for data dictionary, i.e., a description of the data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f7937920-8ae3-4389-9b6f-92b435c5da53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the data to a Pandas dataframe\n",
    "wine_df = pd.DataFrame(wine_data.data, columns=wine_data.feature_names)\n",
    "\n",
    "# Add the target label (add a new column)\n",
    "wine_df['target'] = wine_data.target\n",
    "\n",
    "# Preview\n",
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992c4669-c36c-4440-abda-1f44904503c8",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Before conducting any data analysis, always check the quality of the dataset with exploratory data analysis.\n",
    "* You can call `.info()` method to print out a summary of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1d92a6cb-135f-4c9e-b6b1-f1756f95a7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   alcohol                       178 non-null    float64\n",
      " 1   malic_acid                    178 non-null    float64\n",
      " 2   ash                           178 non-null    float64\n",
      " 3   alcalinity_of_ash             178 non-null    float64\n",
      " 4   magnesium                     178 non-null    float64\n",
      " 5   total_phenols                 178 non-null    float64\n",
      " 6   flavanoids                    178 non-null    float64\n",
      " 7   nonflavanoid_phenols          178 non-null    float64\n",
      " 8   proanthocyanins               178 non-null    float64\n",
      " 9   color_intensity               178 non-null    float64\n",
      " 10  hue                           178 non-null    float64\n",
      " 11  od280/od315_of_diluted_wines  178 non-null    float64\n",
      " 12  proline                       178 non-null    float64\n",
      " 13  target                        178 non-null    int64  \n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 19.6 KB\n"
     ]
    }
   ],
   "source": [
    "wine_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666a1c0f-62e8-41fb-b99f-c0805b20846c",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "* There are 178 data samples with 14 columns including the target column (output that we would like to predict).\n",
    "* Luckily, no missing values are in our dataset from `Non-Null Count`.\n",
    "* All features are `float64` except for target column.\n",
    "* The dataset consumes 19.6 KB of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ff288d89-e926-4e28-a68f-af964852220a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "      <td>0.938202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "      <td>0.775035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
       "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
       "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
       "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
       "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
       "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
       "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
       "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
       "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
       "\n",
       "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "count     178.000000  178.000000            178.000000       178.000000   \n",
       "mean        2.295112    2.029270              0.361854         1.590899   \n",
       "std         0.625851    0.998859              0.124453         0.572359   \n",
       "min         0.980000    0.340000              0.130000         0.410000   \n",
       "25%         1.742500    1.205000              0.270000         1.250000   \n",
       "50%         2.355000    2.135000              0.340000         1.555000   \n",
       "75%         2.800000    2.875000              0.437500         1.950000   \n",
       "max         3.880000    5.080000              0.660000         3.580000   \n",
       "\n",
       "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \\\n",
       "count       178.000000  178.000000                    178.000000   178.000000   \n",
       "mean          5.058090    0.957449                      2.611685   746.893258   \n",
       "std           2.318286    0.228572                      0.709990   314.907474   \n",
       "min           1.280000    0.480000                      1.270000   278.000000   \n",
       "25%           3.220000    0.782500                      1.937500   500.500000   \n",
       "50%           4.690000    0.965000                      2.780000   673.500000   \n",
       "75%           6.200000    1.120000                      3.170000   985.000000   \n",
       "max          13.000000    1.710000                      4.000000  1680.000000   \n",
       "\n",
       "           target  \n",
       "count  178.000000  \n",
       "mean     0.938202  \n",
       "std      0.775035  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      1.000000  \n",
       "75%      2.000000  \n",
       "max      2.000000  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236003c9-dd43-46d1-a97d-73fae18cb918",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "* Since `target` is a categorical variable, we check the frequency and proportion using `.value_counts()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6c004e86-3ebf-4f45-8726-e1e632fedc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>39.887640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>33.146067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>26.966292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count  proportion\n",
       "target                   \n",
       "1          71   39.887640\n",
       "0          59   33.146067\n",
       "2          48   26.966292"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([wine_df['target'].value_counts(), wine_df['target'].value_counts(normalize=True)*100], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0d8b1b-d433-4312-acfc-50efc4e66f65",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Preprocessing is important prior to applying machine learning algorithms.\n",
    "    * Check missing values, outliers, duplicates, errors, and data types.\n",
    "    * Avoid \"Garbage in, garbage out.\"\n",
    "* Machine learning models typically require numerical inputs.\n",
    "* Another practice is to standardize the input (via Z-transform) to make predictors more comparable. \n",
    "    * We do not want predictor A has a magnitude of 10000, while predictor B has a magnitude of 0.1.\n",
    "    * We can achieve the goal using `StandardScaler()` class.\n",
    "    * Each value goes through the following transformation columnwise, i.e., $x = (x - x_{mean})/x_{sd}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "30d2b253-5ee5-4594-9707-5004ced1dab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n"
     ]
    }
   ],
   "source": [
    "# Remember to import standardscaler (code should be written in the beginning of the Jupyter notebook).\n",
    "# Split data into features (input) and label (output)\n",
    "print(wine_data.feature_names)\n",
    "\n",
    "# Always make a copy to avoid making changes on the raw data (when you have sufficient amount of memory).\n",
    "x_mat = wine_df[wine_data.feature_names].copy()\n",
    "y_val = wine_df['target'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9da298-4547-409f-9ff5-f67e1329648c",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "<img src=\"figures/sklearn_flowchart_1.png\" alt=\"drawing\" width=\"900\"/>\n",
    "    \n",
    "* In this flowchart, no output data are involved. We use `.transform()` in the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b7eacfaa-6c63-40b9-bd42-d12ed548946e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(178, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.51861254, -0.5622498 ,  0.23205254, -1.16959318,  1.91390522,\n",
       "        0.80899739,  1.03481896, -0.65956311,  1.22488398,  0.25171685,\n",
       "        0.36217728,  1.84791957,  1.01300893])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate scaler and fit on features\n",
    "scaler_obj = StandardScaler()\n",
    "\n",
    "# apply changes to training data\n",
    "# and update parameters (in this case, no model parameters are available, so this is optional)\n",
    "scaler_obj.fit(x_mat)\n",
    "\n",
    "# apply changes to any data and assign it with another variable\n",
    "x_scaled_mat = scaler_obj.transform(x_mat)\n",
    "\n",
    "# view the transformed output\n",
    "print(type(x_scaled_mat))\n",
    "print(x_scaled_mat.shape)\n",
    "x_scaled_mat[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a459bb-862e-4c49-84c2-47aa0aff4a8e",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* As we previously mentioned, we need to have training and testing set when we perform classification tasks.\n",
    "* If rows of input data are independent of each other, we can randomly select training and testing set.\n",
    "* Sklearn package has a built-in function called `train_test_split()`.\n",
    "* We usually set 70% data to train and 30% to test. The exact ratio vary depending on the volume of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "20bc0777-625c-4780-adab-b7f81478d0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "# remember to import train_test_split in the beginning\n",
    "x_train_scaled, x_test_scaled, y_train, y_test = train_test_split(x_scaled_mat, y_val, train_size=0.7, random_state=1)\n",
    "\n",
    "# Check the splits are correct\n",
    "print(x_train_scaled.shape[0])\n",
    "print(x_test_scaled.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0c7783-41c7-43aa-bdbb-e6284aea7f24",
   "metadata": {},
   "source": [
    "### Model building\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Sklearn has numerous built-in classification methods. We will demonstrate a couple of methods including\n",
    "    * logistic regression\n",
    "    * support vector machine\n",
    "    * decision tree classifier\n",
    "    \n",
    "* <img src=\"figures/sklearn_flowchart_2.png\" alt=\"drawing\" width=\"900\"/>\n",
    "\n",
    "    * In this flowchart, both input and output (in the training set) are involved, so `.predict()` is used finally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cb40ecea-5e32-4d35-85b9-14a2db776698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instnatiating the models \n",
    "# Sometimes, you need to modify the parameters inside each of the function.\n",
    "# If not, the model will use its default values.\n",
    "logistic_obj = LogisticRegression()\n",
    "svm_obj = SVC(probability=True) # probability is set to be False by default.\n",
    "tree_obj = DecisionTreeClassifier()\n",
    "\n",
    "# Training the models \n",
    "logistic_obj.fit(x_train_scaled, y_train)\n",
    "svm_obj.fit(x_train_scaled, y_train)\n",
    "tree_obj.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Making predictions with each model\n",
    "log_reg_preds = logistic_obj.predict(x_test_scaled)\n",
    "svm_preds = svm_obj.predict(x_test_scaled)\n",
    "tree_preds = tree_obj.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0e7134d7-885e-4352-b536-4b5340e0fc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2],\n",
       "       [1, 1, 1],\n",
       "       [0, 0, 0],\n",
       "       [1, 1, 1],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_three_method = np.stack([log_reg_preds, svm_preds, tree_preds], axis=0).T\n",
    "y_preds_three_method[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ddc6d21d-9290-45a1-937e-460b36048966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.63329272e-02 1.34031306e-02 9.60263942e-01]\n",
      " [4.69277794e-04 9.99390372e-01 1.40350652e-04]\n",
      " [9.97118302e-01 2.30543045e-03 5.76267446e-04]\n",
      " [8.50282835e-03 9.91447420e-01 4.97517215e-05]\n",
      " [9.99257734e-01 2.14428342e-04 5.27837453e-04]]\n",
      "[[0.0108554  0.01409034 0.97505427]\n",
      " [0.00332249 0.99504603 0.00163148]\n",
      " [0.98987005 0.00319413 0.00693582]\n",
      " [0.03524411 0.93126552 0.03349038]\n",
      " [0.98826474 0.00329393 0.00844133]]\n",
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# You can view the probability vector per measure per method.\n",
    "log_reg_probs = logistic_obj.predict_proba(x_test_scaled)\n",
    "svm_probs = svm_obj.predict_proba(x_test_scaled)\n",
    "tree_probs = tree_obj.predict_proba(x_test_scaled)\n",
    "print(log_reg_probs[:5,:])\n",
    "print(svm_probs[:5,:])\n",
    "print(tree_probs[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed927f6-e723-4ed2-a972-0ba05add1976",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* In our case, we will use `classification_report()` to build a text report showing main classification metrics such as `precision`, `recall`, `f1_score`, `accuracy`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b856b675-5f55-48b6-8bcf-8ffec1ab6ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      " {'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 23.0}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 19.0}, '2': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 12.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 54.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 54.0}}\n",
      "\n",
      "Support Vector Machine Results:\n",
      " {'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 23.0}, '1': {'precision': 0.95, 'recall': 1.0, 'f1-score': 0.9743589743589743, 'support': 19.0}, '2': {'precision': 1.0, 'recall': 0.9166666666666666, 'f1-score': 0.9565217391304348, 'support': 12.0}, 'accuracy': 0.9814814814814815, 'macro avg': {'precision': 0.9833333333333334, 'recall': 0.9722222222222222, 'f1-score': 0.976960237829803, 'support': 54.0}, 'weighted avg': {'precision': 0.9824074074074074, 'recall': 0.9814814814814815, 'f1-score': 0.981316321896032, 'support': 54.0}}\n",
      "\n",
      "Decision Tree Results:\n",
      " {'0': {'precision': 1.0, 'recall': 0.9565217391304348, 'f1-score': 0.9777777777777777, 'support': 23.0}, '1': {'precision': 0.9473684210526315, 'recall': 0.9473684210526315, 'f1-score': 0.9473684210526315, 'support': 19.0}, '2': {'precision': 0.9230769230769231, 'recall': 1.0, 'f1-score': 0.96, 'support': 12.0}, 'accuracy': 0.9629629629629629, 'macro avg': {'precision': 0.9568151147098515, 'recall': 0.9679633867276888, 'f1-score': 0.9617153996101364, 'support': 54.0}, 'weighted avg': {'precision': 0.9643874643874645, 'recall': 0.9629629629629629, 'f1-score': 0.9631275720164609, 'support': 54.0}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import classification_report (put it in the beginning)\n",
    "# Store model predictions in a dictionary\n",
    "# this makes it easier to iterate through each model\n",
    "# and print the results. \n",
    "model_preds = {\n",
    "    \"Logistic Regression\": log_reg_preds,\n",
    "    \"Support Vector Machine\": svm_preds,\n",
    "    \"Decision Tree\": tree_preds\n",
    "}\n",
    "\n",
    "for model, preds in model_preds.items():\n",
    "    print('{} Results:\\n {}\\n'.format(model, classification_report(y_test, preds, output_dict=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2f9de809-15bc-440f-b76d-bfdb164fbdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       1.00      1.00      1.00        19\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        54\n",
      "   macro avg       1.00      1.00      1.00        54\n",
      "weighted avg       1.00      1.00      1.00        54\n",
      "\n",
      "Support Vector Machine Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       0.95      1.00      0.97        19\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.98        54\n",
      "   macro avg       0.98      0.97      0.98        54\n",
      "weighted avg       0.98      0.98      0.98        54\n",
      "\n",
      "Decision Tree Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        23\n",
      "           1       0.95      0.95      0.95        19\n",
      "           2       0.92      1.00      0.96        12\n",
      "\n",
      "    accuracy                           0.96        54\n",
      "   macro avg       0.96      0.97      0.96        54\n",
      "weighted avg       0.96      0.96      0.96        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model, preds in model_preds.items():\n",
    "    print(f\"{model} Results:\\n{classification_report(y_test, preds)}\", sep=\"\\n\\n\") # output_dict=False by default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83993ee6-7db1-441a-b46a-d21a986e3168",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "The reported averages include \n",
    "\n",
    "* (sample) average (only for multilabel classification). \n",
    "* macro average (averaging the unweighted mean per label), \n",
    "* weighted average (averaging the support-weighted mean per label).\n",
    "\n",
    "Which method performs the best?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
